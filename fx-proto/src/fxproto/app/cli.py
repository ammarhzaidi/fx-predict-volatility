# fx-proto/src/fxproto/app/cli.py
from __future__ import annotations
import typer
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Optional

from fxproto.config.loader import get_config, resolved_outputs_dir
from fxproto.data.preprocess import load_or_fetch, train_test_split_by_dates, scale_train_apply_test
from fxproto.data.features import prepare_model_data, get_feature_columns, make_supervised_windows
from fxproto.models.lstm import TinyLSTM, GraphEnhancedLSTM, train_model, create_adjacency_mask, prepare_graph_data
from fxproto.models.infer import predict_series, add_predictions_to_frame
from fxproto.graphdemo.graph_build import build_financial_graph
from fxproto.graphdemo.visualize import create_dashboard_plots
from fxproto.graphdemo.message_passing import GraphMessagePassing

app = typer.Typer(add_completion=False)


@app.command()
def forecast(
        use_graph: bool = typer.Option(True, "--use-graph", help="Use graph-enhanced model"),
        pair: Optional[str] = typer.Option(None, "--pair", help="Override config pair"),
        epochs: int = typer.Option(25, "--epochs", help="Training epochs"),
        save_plots: bool = typer.Option(True, "--save-plots", help="Save visualization plots")
):
    """
    Enhanced forecast command with graph integration.
    Fetch ‚Üí preprocess ‚Üí features ‚Üí train LSTM/GraphLSTM ‚Üí predict ‚Üí visualize.
    """
    print("üöÄ Starting enhanced forex forecasting...")

    # Load configuration
    cfg = get_config()
    pair = pair or cfg.settings.pair
    interval = cfg.data.interval
    dates = cfg.settings.dates
    horizon = cfg.settings.horizon

    # Setup output directories
    out_dir = resolved_outputs_dir()
    (out_dir / "charts").mkdir(parents=True, exist_ok=True)
    (out_dir / "reports").mkdir(parents=True, exist_ok=True)
    (out_dir / "models").mkdir(parents=True, exist_ok=True)

    print(f"üìä Processing {pair} with {horizon}-step horizon")

    # 1. Load and prepare data
    print("üìà Loading and preparing data...")
    df = load_or_fetch(pair, dates.train_start, dates.test_end, interval)
    df_enhanced, available_features = prepare_model_data(df, include_synthetic=use_graph)

    print(f"   ‚Ä¢ Loaded {len(df)} price records")
    print(f"   ‚Ä¢ Generated {len(available_features)} features: {available_features[:5]}...")

    # 2. Train/test split and scaling
    print("üîÑ Splitting and scaling data...")
    train, test = train_test_split_by_dates(df_enhanced)

    # Select features for model
    price_features = ["ret_1", "ma_5", "vol_10", "rsi_14"]
    price_features = [f for f in price_features if f in available_features]

    target_col = "Close"
    train_scaled, test_scaled, scaler = scale_train_apply_test(
        train, test, cols=price_features
    )

    print(f"   ‚Ä¢ Train: {len(train_scaled)} samples")
    print(f"   ‚Ä¢ Test: {len(test_scaled)} samples")
    print(f"   ‚Ä¢ Using features: {price_features}")

    # 3. Create supervised windows
    print("ü™ü Creating supervised learning windows...")
    lookback = 30

    X_train, y_train = make_supervised_windows(
        train_scaled, price_features, target_col, lookback, horizon
    )
    X_test, y_test = make_supervised_windows(
        test_scaled, price_features, target_col, lookback, horizon
    )

    print(f"   ‚Ä¢ Train windows: {X_train.shape}")
    print(f"   ‚Ä¢ Test windows: {X_test.shape}")

    # 4. Prepare graph data if using graph model
    X_train_graph, X_test_graph, adjacency_mask = None, None, None

    if use_graph:
        print("üï∏Ô∏è Preparing graph features...")

        # Build financial graph
        graph = build_financial_graph()
        node_features = graph.get_node_features_from_data(df_enhanced)

        # Create adjacency mask
        edges = [(e.source, e.target) for e in cfg.graph.edges]
        adjacency_mask = create_adjacency_mask(graph.node_list, edges)

        # Prepare graph data aligned with LSTM windows
        train_window_indices = np.arange(lookback, len(train_scaled) - horizon)
        test_window_indices = np.arange(lookback, len(test_scaled) - horizon)

        X_train_graph = prepare_graph_data(node_features, train_window_indices)
        X_test_graph = prepare_graph_data(node_features, test_window_indices)

        print(f"   ‚Ä¢ Graph nodes: {len(graph.node_list)}")
        print(f"   ‚Ä¢ Graph edges: {len(edges)}")
        print(f"   ‚Ä¢ Train graph data: {X_train_graph.shape}")
        print(f"   ‚Ä¢ Test graph data: {X_test_graph.shape}")

    # 5. Create and train model
    print("ü§ñ Creating and training model...")

    if use_graph and X_train_graph is not None:
        model = GraphEnhancedLSTM(
            n_price_features=len(price_features),
            n_graph_nodes=len(graph.node_list),
            lstm_hidden=64,
            graph_hidden=32
        )
        print("   ‚Ä¢ Using GraphEnhancedLSTM")
        model = train_model(
            model, X_train, y_train, epochs=epochs, lr=1e-3,
            X_graph=X_train_graph
        )
    else:
        model = TinyLSTM(n_features=len(price_features), hidden=64)
        print("   ‚Ä¢ Using TinyLSTM baseline")
        model = train_model(model, X_train, y_train, epochs=epochs, lr=1e-3)

    # 6. Generate predictions
    print("üîÆ Generating predictions...")

    if use_graph and X_test_graph is not None:
        # For graph model, need to handle predictions differently
        import torch
        model.eval()
        with torch.no_grad():
            X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
            X_graph_tensor = torch.tensor(X_test_graph, dtype=torch.float32)
            predictions, attention_weights = model(X_test_tensor, X_graph_tensor, adjacency_mask)
            predictions = predictions.cpu().numpy()
    else:
        predictions = predict_series(model, X_test)

    # 7. Align predictions with original timeline
    start_idx = len(train) + lookback
    report = add_predictions_to_frame(df_enhanced, start_idx, predictions, target_col, horizon)

    # Calculate metrics
    actual = report['actual'].dropna()
    pred = report['pred'][actual.index]

    mse = np.mean((actual - pred) ** 2)
    mae = np.mean(np.abs(actual - pred))

    # Directional accuracy
    actual_direction = (actual.diff() > 0).astype(int)
    pred_direction = (pred.diff() > 0).astype(int)
    directional_accuracy = (actual_direction == pred_direction).mean()

    print(f"\nüìä Model Performance:")
    print(f"   ‚Ä¢ MSE: {mse:.6f}")
    print(f"   ‚Ä¢ MAE: {mae:.6f}")
    print(f"   ‚Ä¢ Directional Accuracy: {directional_accuracy:.3f}")

    # 8. Save results
    print("üíæ Saving results...")

    # Save CSV report
    csv_path = out_dir / "reports" / f"{pair}_forecast_h{horizon}.csv"
    report_with_metrics = report.copy()
    report_with_metrics.attrs['mse'] = mse
    report_with_metrics.attrs['mae'] = mae
    report_with_metrics.attrs['directional_accuracy'] = directional_accuracy
    report.to_csv(csv_path, index=True)

    # Save model
    import torch
    model_path = out_dir / "models" / f"{pair}_model_h{horizon}.pt"
    torch.save(model.state_dict(), model_path)

    print(f"   ‚Ä¢ Report: {csv_path}")
    print(f"   ‚Ä¢ Model: {model_path}")

    # 9. Create visualizations
    if save_plots:
        print("üìà Creating visualizations...")

        try:
            # Create comprehensive dashboard plots
            plots = create_dashboard_plots(
                scenario_id="EU_negative_GDP_shock",
                df=df_enhanced,
                predictions=predictions,
                output_dir=str(out_dir / "charts")
            )

            print(f"   ‚Ä¢ Network plot: {plots['network_plot']}")
            print(f"   ‚Ä¢ Impact plot: {plots['impact_plot']}")
            if plots['forecast_plot']:
                print(f"   ‚Ä¢ Forecast plot: {plots['forecast_plot']}")

        except Exception as e:
            print(f"   ‚ö†Ô∏è Plotting failed: {e}")

    print("‚úÖ Forecast complete!")


@app.command()
def graphdemo(
        scenario: str = typer.Option("EU_negative_GDP_shock", "--scenario", help="Scenario ID to simulate"),
        steps: int = typer.Option(3, "--steps", help="Propagation steps"),
        save_plots: bool = typer.Option(True, "--save-plots", help="Save plots")
):
    """
    Run graph scenario simulation and visualization.
    """
    print(f"üï∏Ô∏è Running graph demo for scenario: {scenario}")

    # Setup
    out_dir = resolved_outputs_dir()
    (out_dir / "charts").mkdir(parents=True, exist_ok=True)

    try:
        # Build graph
        print("üèóÔ∏è Building financial graph...")
        graph = build_financial_graph()
        message_passer = GraphMessagePassing(graph)

        print(f"   ‚Ä¢ Nodes: {len(graph.node_list)}")
        print(f"   ‚Ä¢ Edges: {len(graph.cfg.edges)}")

        # Run scenario analysis
        print(f"‚ö° Running scenario: {scenario}")
        analysis = message_passer.analyze_influence_paths(scenario)

        if analysis:
            print(f"   ‚Ä¢ Initial shock magnitude: {analysis['initial_shock']:.4f}")
            print(f"   ‚Ä¢ Final magnitude: {analysis['final_magnitude']:.4f}")
            print(f"   ‚Ä¢ Amplification factor: {analysis['amplification_factor']:.2f}")

            print("   ‚Ä¢ Most influenced nodes:")
            for node, impact in analysis['most_influenced_nodes']:
                print(f"     - {node}: {impact:.4f}")

        # Create plots
        if save_plots:
            print("üìä Creating visualization plots...")
            plots = create_dashboard_plots(
                scenario_id=scenario,
                df=pd.DataFrame(),  # Empty df for graph-only plots
                output_dir=str(out_dir / "charts")
            )

            print(f"   ‚Ä¢ Network plot: {plots['network_plot']}")
            print(f"   ‚Ä¢ Impact plot: {plots['impact_plot']}")

        print("‚úÖ Graph demo complete!")

    except Exception as e:
        print(f"‚ùå Graph demo failed: {e}")
        import traceback
        traceback.print_exc()


@app.command()
def backtest(
        pairs: Optional[str] = typer.Option("EURUSD,GBPUSD", "--pairs", help="Comma-separated pairs"),
        horizons: Optional[str] = typer.Option("1,5,10", "--horizons", help="Comma-separated horizons"),
        use_graph: bool = typer.Option(True, "--use-graph", help="Use graph models")
):
    """
    Run systematic backtesting across multiple pairs and horizons.
    """
    print("üîÑ Starting systematic backtest...")

    pair_list = [p.strip() for p in pairs.split(",")]
    horizon_list = [int(h.strip()) for h in horizons.split(",")]

    results = []

    for pair in pair_list:
        for horizon in horizon_list:
            print(f"\nüìä Testing {pair} with horizon {horizon}")

            try:
                # Update config temporarily
                cfg = get_config()
                original_pair = cfg.settings.pair
                original_horizon = cfg.settings.horizon

                # Run forecast (this is a simplified version)
                # In practice, you'd want to modify the config or pass parameters

                # For now, just print what would be tested
                print(f"   ‚Ä¢ Would test: {pair} h={horizon} graph={use_graph}")

                # Placeholder results
                results.append({
                    'pair': pair,
                    'horizon': horizon,
                    'use_graph': use_graph,
                    'mse': np.random.uniform(0.0001, 0.001),
                    'mae': np.random.uniform(0.01, 0.05),
                    'directional_accuracy': np.random.uniform(0.45, 0.65)
                })

            except Exception as e:
                print(f"   ‚ùå Failed: {e}")
                results.append({
                    'pair': pair,
                    'horizon': horizon,
                    'use_graph': use_graph,
                    'mse': np.nan,
                    'mae': np.nan,
                    'directional_accuracy': np.nan
                })

    # Save backtest results
    results_df = pd.DataFrame(results)
    out_dir = resolved_outputs_dir()
    results_path = out_dir / "reports" / "backtest_results.csv"
    results_df.to_csv(results_path, index=False)

    print(f"\nüìà Backtest Summary:")
    print(results_df.groupby(['use_graph']).agg({
        'mse': 'mean',
        'mae': 'mean',
        'directional_accuracy': 'mean'
    }).round(4))

    print(f"üíæ Results saved to: {results_path}")
    print("‚úÖ Backtest complete!")


@app.command()
def info():
    """Display configuration and system information."""
    print("‚ÑπÔ∏è FX Proto System Information\n")

    # Config info
    cfg = get_config()
    print("üìã Configuration:")
    print(f"   ‚Ä¢ Pair: {cfg.settings.pair}")
    print(f"   ‚Ä¢ Horizon: {cfg.settings.horizon}")
    print(f"   ‚Ä¢ Train period: {cfg.settings.dates.train_start} to {cfg.settings.dates.train_end}")
    print(f"   ‚Ä¢ Test period: {cfg.settings.dates.test_start} to {cfg.settings.dates.test_end}")
    print(f"   ‚Ä¢ Data source: {cfg.data.source}")
    print(f"   ‚Ä¢ Interval: {cfg.data.interval}")

    # Graph info
    print(f"\nüï∏Ô∏è Graph Configuration:")
    print(f"   ‚Ä¢ Nodes: {len(cfg.graph.nodes)} ({[n.id for n in cfg.graph.nodes]})")
    print(f"   ‚Ä¢ Edges: {len(cfg.graph.edges)}")
    print(f"   ‚Ä¢ Scenarios: {len(cfg.graph.scenarios)} ({[s.id for s in cfg.graph.scenarios]})")

    # Paths
    print(f"\nüìÅ Paths:")
    print(f"   ‚Ä¢ Data dir: {resolved_outputs_dir().parent / 'data'}")
    print(f"   ‚Ä¢ Outputs dir: {resolved_outputs_dir()}")

    # Check data availability
    try:
        df = load_or_fetch(cfg.settings.pair, cfg.settings.dates.train_start,
                           cfg.settings.dates.test_end, cfg.data.interval)
        print(f"\nüìà Data Status:")
        print(f"   ‚Ä¢ Records available: {len(df)}")
        print(f"   ‚Ä¢ Date range: {df.index.min()} to {df.index.max()}")
        print(f"   ‚Ä¢ Latest price: {df['Close'].iloc[-1]:.5f}")
    except Exception as e:
        print(f"\n‚ùå Data loading failed: {e}")


if __name__ == "__main__":
    app()